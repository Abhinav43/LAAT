04:13:22 INFO Training with 
{   'attention_mode': 'label',
    'batch_size': 8,
    'best_model_path': None,
    'bidirectional': 1,
    'd_a': 512,
    'dropout': 0.3,
    'embedding_file': 'data/embeddings/word2vec_sg0_100.model',
    'embedding_mode': 'word2vec',
    'embedding_size': 100,
    'exp_name': 'bothconcattahn',
    'hidden_size': 512,
    'joint_mode': 'hierarchical',
    'level_projection_size': 128,
    'lr': 0.001,
    'lr_scheduler_factor': 0.9,
    'lr_scheduler_patience': 5,
    'main_metric': 'micro_f1',
    'max_seq_length': 4000,
    'metric_level': 1,
    'min_seq_length': -1,
    'min_word_frequency': -1,
    'mode': 'static',
    'model': <class 'src.models.rnn.RNN'>,
    'multilabel': 1,
    'n_epoch': 2,
    'n_layers': 1,
    'optimiser': 'adamw',
    'patience': 5,
    'penalisation_coeff': 0.01,
    'problem_name': 'mimic-iii_2_50',
    'r': -1,
    'resume_training': False,
    'rnn_model': 'LSTM',
    'save_best_model': 1,
    'save_results': 1,
    'save_results_on_train': False,
    'shuffle_data': 1,
    'use_last_hidden_state': 0,
    'use_lr_scheduler': 1,
    'use_regularisation': False,
    'weight_decay': 0}

04:13:22 INFO Loaded vocab and data from file
04:13:22 INFO Using cuda:2
04:13:22 INFO # levels: 2
04:13:22 INFO # labels at level 0: 40
04:13:22 INFO # labels at level 1: 50
04:13:22 INFO 8066.1573.1729
04:13:25 INFO Saved dataset path: cached_data/mimic-iii_2_50/797d28c2de5595caf911a3ed71f510b1.data.pkl
04:13:26 INFO 8066 instances with 12243046 tokens, Level_0 with 40 labels, Level_1 with 50 labels in the train dataset
04:13:26 INFO 1729 instances with 3140441 tokens, Level_0 with 40 labels, Level_1 with 50 labels in the valid dataset
04:13:26 INFO 1729 instances with 3140441 tokens, Level_0 with 40 labels, Level_1 with 50 labels in the test dataset
04:13:26 INFO Training epoch #1
04:19:33 INFO Learning rate at epoch #1: 0.001
04:19:33 INFO Loss on Train at epoch #1: 0.24759, micro_f1 on Valid: 0.63679
04:19:33 INFO [NEW BEST] (level_1) micro_f1 on Valid set: 0.63679
04:19:33 INFO Results on Valid set at epoch #1 with Averaged Loss 0.20801
04:19:33 INFO ======== Results at level_0 ========
04:19:33 INFO Results on Valid set at epoch #1 with Loss 0.21305: 
[MICRO]	accuracy: 0.50885	auc: 0.92814	precision: 0.75719	recall: 0.60808	f1: 0.67449	P@1: 0	P@5: 0	P@8: 0	P@10: 0	P@15: 0
[MACRO]	accuracy: 0.41654	auc: 0.90052	precision: 0.65555	recall: 0.5133	f1: 0.57577	P@1: 0.86466	P@5: 0.64673	P@8: 0.52458	P@10: 0.45951	P@15: 0.34286

04:19:33 INFO ======== Results at level_1 ========
04:19:34 INFO Results on Valid set at epoch #1 with Loss 0.20398: 
[MICRO]	accuracy: 0.46712	auc: 0.921	precision: 0.71259	recall: 0.57556	f1: 0.63679	P@1: 0	P@5: 0	P@8: 0	P@10: 0	P@15: 0
[MACRO]	accuracy: 0.39335	auc: 0.89745	precision: 0.6176	recall: 0.49695	f1: 0.55075	P@1: 0.82302	P@5: 0.62036	P@8: 0.50622	P@10: 0.44719	P@15: 0.34232

04:19:34 INFO Training epoch #2
04:25:43 INFO Learning rate at epoch #2: 0.001
04:25:43 INFO Loss on Train at epoch #2: 0.18996, micro_f1 on Valid: 0.69475
04:25:43 INFO [NEW BEST] (level_1) micro_f1 on Valid set: 0.69475
04:25:43 INFO Results on Valid set at epoch #2 with Averaged Loss 0.1978
04:25:43 INFO ======== Results at level_0 ========
04:25:43 INFO Results on Valid set at epoch #2 with Loss 0.20416: 
[MICRO]	accuracy: 0.57261	auc: 0.93657	precision: 0.74284	recall: 0.71418	f1: 0.72823	P@1: 0	P@5: 0	P@8: 0	P@10: 0	P@15: 0
[MACRO]	accuracy: 0.50605	auc: 0.90973	precision: 0.68525	recall: 0.64228	f1: 0.66307	P@1: 0.87854	P@5: 0.66339	P@8: 0.53492	P@10: 0.4675	P@15: 0.34675

04:25:43 INFO ======== Results at level_1 ========
04:25:43 INFO Results on Valid set at epoch #2 with Loss 0.19271: 
[MICRO]	accuracy: 0.53228	auc: 0.93135	precision: 0.71823	recall: 0.67276	f1: 0.69475	P@1: 0	P@5: 0	P@8: 0	P@10: 0	P@15: 0
[MACRO]	accuracy: 0.47178	auc: 0.90753	precision: 0.64526	recall: 0.6047	f1: 0.62432	P@1: 0.85541	P@5: 0.64419	P@8: 0.52444	P@10: 0.4598	P@15: 0.34764

04:25:43 INFO =================== BEST ===================
04:25:43 INFO Results on Valid set at epoch #2 with Averaged Loss 0.1978
04:25:43 INFO ======== Results at level_0 ========
04:25:43 INFO Results on Valid set at epoch #2 with Loss 0.20416: 
[MICRO]	accuracy: 0.57261	auc: 0.93657	precision: 0.74284	recall: 0.71418	f1: 0.72823	P@1: 0	P@5: 0	P@8: 0	P@10: 0	P@15: 0
[MACRO]	accuracy: 0.50605	auc: 0.90973	precision: 0.68525	recall: 0.64228	f1: 0.66307	P@1: 0.87854	P@5: 0.66339	P@8: 0.53492	P@10: 0.4675	P@15: 0.34675

04:25:43 INFO ======== Results at level_1 ========
04:25:43 INFO Results on Valid set at epoch #2 with Loss 0.19271: 
[MICRO]	accuracy: 0.53228	auc: 0.93135	precision: 0.71823	recall: 0.67276	f1: 0.69475	P@1: 0	P@5: 0	P@8: 0	P@10: 0	P@15: 0
[MACRO]	accuracy: 0.47178	auc: 0.90753	precision: 0.64526	recall: 0.6047	f1: 0.62432	P@1: 0.85541	P@5: 0.64419	P@8: 0.52444	P@10: 0.4598	P@15: 0.34764

04:25:43 INFO => loading best model 'checkpoints/mimic-iii_2_50/RNN_LSTM_1_512.static.label.0.001.0.3_e9737fc0e92e1510f2bbc80e7bcfff05/best_model.pkl'
