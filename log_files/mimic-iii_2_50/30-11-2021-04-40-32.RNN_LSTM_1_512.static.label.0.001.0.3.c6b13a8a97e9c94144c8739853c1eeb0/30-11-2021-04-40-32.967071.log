04:40:32 INFO Training with 
{   'attention_mode': 'label',
    'batch_size': 8,
    'best_model_path': None,
    'bidirectional': 1,
    'd_a': 512,
    'dropout': 0.3,
    'embedding_file': 'data/embeddings/word2vec_sg0_100.model',
    'embedding_mode': 'word2vec',
    'embedding_size': 100,
    'exp_name': 'experiment_none',
    'hidden_size': 512,
    'joint_mode': 'hierarchical',
    'level_projection_size': 128,
    'loss_name': 'FL',
    'lr': 0.001,
    'lr_scheduler_factor': 0.9,
    'lr_scheduler_patience': 5,
    'main_metric': 'micro_f1',
    'max_seq_length': 4000,
    'metric_level': 1,
    'min_seq_length': -1,
    'min_word_frequency': -1,
    'mode': 'static',
    'model': <class 'src.models.rnn.RNN'>,
    'multilabel': 1,
    'n_epoch': 50,
    'n_layers': 1,
    'optimiser': 'adamw',
    'patience': 5,
    'penalisation_coeff': 0.01,
    'problem_name': 'mimic-iii_2_50',
    'r': -1,
    'reduction': 'none',
    'resume_training': False,
    'rnn_model': 'LSTM',
    'save_best_model': 1,
    'save_results': 1,
    'save_results_on_train': False,
    'shuffle_data': 1,
    'use_last_hidden_state': 0,
    'use_lr_scheduler': 1,
    'use_regularisation': False,
    'weight_decay': 0}

04:40:33 INFO Loaded vocab and data from file
04:40:33 INFO Using cuda:2
04:40:33 INFO # levels: 2
04:40:33 INFO # labels at level 0: 40
04:40:33 INFO # labels at level 1: 50
04:40:33 INFO 8066.1573.1729
04:40:35 INFO Saved dataset path: cached_data/mimic-iii_2_50/797d28c2de5595caf911a3ed71f510b1.data.pkl
04:40:36 INFO 8066 instances with 12243046 tokens, Level_0 with 40 labels, Level_1 with 50 labels in the train dataset
04:40:36 INFO 1729 instances with 3140441 tokens, Level_0 with 40 labels, Level_1 with 50 labels in the valid dataset
04:40:36 INFO 1729 instances with 3140441 tokens, Level_0 with 40 labels, Level_1 with 50 labels in the test dataset
04:40:36 INFO Training epoch #1
04:48:07 INFO Learning rate at epoch #1: 0.001
04:48:07 INFO Loss on Train at epoch #1: 0.03346, micro_f1 on Valid: 0.64342
04:48:07 INFO [NEW BEST] (level_1) micro_f1 on Valid set: 0.64342
04:48:07 INFO Results on Valid set at epoch #1 with Averaged Loss 0.0279
04:48:07 INFO ======== Results at level_0 ========
04:48:07 INFO Results on Valid set at epoch #1 with Loss 0.02866: 
[MICRO]	accuracy: 0.51604	auc: 0.93002	precision: 0.7315	recall: 0.63663	f1: 0.68078	P@1: 0	P@5: 0	P@8: 0	P@10: 0	P@15: 0
[MACRO]	accuracy: 0.44151	auc: 0.90786	precision: 0.65391	recall: 0.56089	f1: 0.60384	P@1: 0.86235	P@5: 0.64962	P@8: 0.52407	P@10: 0.45882	P@15: 0.34513

04:48:07 INFO ======== Results at level_1 ========
04:48:07 INFO Results on Valid set at epoch #1 with Loss 0.02729: 
[MICRO]	accuracy: 0.4743	auc: 0.92449	precision: 0.69714	recall: 0.5974	f1: 0.64342	P@1: 0	P@5: 0	P@8: 0	P@10: 0	P@15: 0
[MACRO]	accuracy: 0.43231	auc: 0.90616	precision: 0.62804	recall: 0.55492	f1: 0.58922	P@1: 0.82938	P@5: 0.62441	P@8: 0.50802	P@10: 0.45055	P@15: 0.34417

04:48:07 INFO Training epoch #2
04:55:41 INFO Learning rate at epoch #2: 0.001
04:55:41 INFO Loss on Train at epoch #2: 0.02567, micro_f1 on Valid: 0.68948
04:55:41 INFO [NEW BEST] (level_1) micro_f1 on Valid set: 0.68948
04:55:41 INFO Results on Valid set at epoch #2 with Averaged Loss 0.02745
04:55:41 INFO ======== Results at level_0 ========
04:55:41 INFO Results on Valid set at epoch #2 with Loss 0.02852: 
[MICRO]	accuracy: 0.56268	auc: 0.93486	precision: 0.71733	recall: 0.72299	f1: 0.72015	P@1: 0	P@5: 0	P@8: 0	P@10: 0	P@15: 0
[MACRO]	accuracy: 0.50334	auc: 0.91458	precision: 0.64232	recall: 0.66458	f1: 0.65326	P@1: 0.8716	P@5: 0.66235	P@8: 0.5347	P@10: 0.46536	P@15: 0.34629

04:55:41 INFO ======== Results at level_1 ========
04:55:41 INFO Results on Valid set at epoch #2 with Loss 0.02659: 
[MICRO]	accuracy: 0.52611	auc: 0.93249	precision: 0.69797	recall: 0.68119	f1: 0.68948	P@1: 0	P@5: 0	P@8: 0	P@10: 0	P@15: 0
[MACRO]	accuracy: 0.47461	auc: 0.91391	precision: 0.6347	recall: 0.62584	f1: 0.63024	P@1: 0.845	P@5: 0.64384	P@8: 0.52429	P@10: 0.46194	P@15: 0.34891

04:55:41 INFO Training epoch #3
05:03:07 INFO Learning rate at epoch #3: 0.001
05:03:07 INFO Loss on Train at epoch #3: 0.02406, micro_f1 on Valid: 0.67389
05:03:07 INFO [CURRENT BEST] (level_1) micro_f1 on Valid set: 0.68948
05:03:07 INFO Early stopping: 1/6
05:03:07 INFO Training epoch #4
05:10:41 INFO Learning rate at epoch #4: 0.001
05:10:41 INFO Loss on Train at epoch #4: 0.02303, micro_f1 on Valid: 0.69753
05:10:41 INFO [NEW BEST] (level_1) micro_f1 on Valid set: 0.69753
05:10:41 INFO Results on Valid set at epoch #4 with Averaged Loss 0.02658
05:10:41 INFO ======== Results at level_0 ========
05:10:41 INFO Results on Valid set at epoch #4 with Loss 0.02706: 
[MICRO]	accuracy: 0.57907	auc: 0.94434	precision: 0.73878	recall: 0.72816	f1: 0.73343	P@1: 0	P@5: 0	P@8: 0	P@10: 0	P@15: 0
[MACRO]	accuracy: 0.52637	auc: 0.92274	precision: 0.67624	recall: 0.67771	f1: 0.67697	P@1: 0.87681	P@5: 0.67311	P@8: 0.54714	P@10: 0.47733	P@15: 0.35215

05:10:41 INFO ======== Results at level_1 ========
05:10:41 INFO Results on Valid set at epoch #4 with Loss 0.0262: 
[MICRO]	accuracy: 0.53554	auc: 0.93806	precision: 0.69314	recall: 0.70197	f1: 0.69753	P@1: 0	P@5: 0	P@8: 0	P@10: 0	P@15: 0
[MACRO]	accuracy: 0.49572	auc: 0.92008	precision: 0.66135	recall: 0.66244	f1: 0.66189	P@1: 0.84905	P@5: 0.65344	P@8: 0.52942	P@10: 0.46796	P@15: 0.35354

05:10:41 INFO Training epoch #5
05:18:15 INFO Learning rate at epoch #5: 0.001
05:18:15 INFO Loss on Train at epoch #5: 0.02203, micro_f1 on Valid: 0.7091
05:18:15 INFO [NEW BEST] (level_1) micro_f1 on Valid set: 0.7091
05:18:15 INFO Results on Valid set at epoch #5 with Averaged Loss 0.0259
05:18:15 INFO ======== Results at level_0 ========
05:18:15 INFO Results on Valid set at epoch #5 with Loss 0.02665: 
[MICRO]	accuracy: 0.58285	auc: 0.94657	precision: 0.7563	recall: 0.71763	f1: 0.73645	P@1: 0	P@5: 0	P@8: 0	P@10: 0	P@15: 0
[MACRO]	accuracy: 0.52382	auc: 0.92698	precision: 0.70764	recall: 0.64481	f1: 0.67477	P@1: 0.88837	P@5: 0.67808	P@8: 0.54822	P@10: 0.47831	P@15: 0.35365

05:18:15 INFO ======== Results at level_1 ========
05:18:15 INFO Results on Valid set at epoch #5 with Loss 0.0253: 
[MICRO]	accuracy: 0.5493	auc: 0.94252	precision: 0.72132	recall: 0.69728	f1: 0.7091	P@1: 0	P@5: 0	P@8: 0	P@10: 0	P@15: 0
[MACRO]	accuracy: 0.50015	auc: 0.92246	precision: 0.67475	recall: 0.63226	f1: 0.65282	P@1: 0.86524	P@5: 0.66628	P@8: 0.54078	P@10: 0.4742	P@15: 0.35674

05:18:15 INFO Training epoch #6
05:25:46 INFO Learning rate at epoch #6: 0.001
05:25:46 INFO Loss on Train at epoch #6: 0.02125, micro_f1 on Valid: 0.70213
05:25:46 INFO [CURRENT BEST] (level_1) micro_f1 on Valid set: 0.7091
05:25:46 INFO Early stopping: 1/6
05:25:46 INFO Training epoch #7
05:33:20 INFO Learning rate at epoch #7: 0.001
05:33:20 INFO Loss on Train at epoch #7: 0.02048, micro_f1 on Valid: 0.69836
05:33:20 INFO [CURRENT BEST] (level_1) micro_f1 on Valid set: 0.7091
05:33:20 INFO Early stopping: 2/6
05:33:20 INFO Training epoch #8
05:40:52 INFO Learning rate at epoch #8: 0.001
05:40:52 INFO Loss on Train at epoch #8: 0.01979, micro_f1 on Valid: 0.69623
05:40:52 INFO [CURRENT BEST] (level_1) micro_f1 on Valid set: 0.7091
05:40:52 INFO Early stopping: 3/6
05:40:52 INFO Training epoch #9
05:48:19 INFO Learning rate at epoch #9: 0.001
05:48:19 INFO Loss on Train at epoch #9: 0.01912, micro_f1 on Valid: 0.68652
05:48:19 INFO [CURRENT BEST] (level_1) micro_f1 on Valid set: 0.7091
05:48:19 INFO Early stopping: 4/6
05:48:19 INFO Training epoch #10
05:55:54 INFO Learning rate at epoch #10: 0.001
05:55:54 INFO Loss on Train at epoch #10: 0.01853, micro_f1 on Valid: 0.6838
05:55:54 INFO [CURRENT BEST] (level_1) micro_f1 on Valid set: 0.7091
05:55:54 INFO Early stopping: 5/6
05:55:54 INFO Training epoch #11
06:03:26 INFO Learning rate at epoch #11: 0.0009000000000000001
06:03:26 INFO Loss on Train at epoch #11: 0.01801, micro_f1 on Valid: 0.68953
06:03:26 INFO [CURRENT BEST] (level_1) micro_f1 on Valid set: 0.7091
06:03:26 INFO Early stopping: 6/6
06:03:26 WARNING Early stopped on Valid set!
06:03:26 INFO =================== BEST ===================
06:03:26 INFO Results on Valid set at epoch #5 with Averaged Loss 0.0259
06:03:26 INFO ======== Results at level_0 ========
06:03:26 INFO Results on Valid set at epoch #5 with Loss 0.02665: 
[MICRO]	accuracy: 0.58285	auc: 0.94657	precision: 0.7563	recall: 0.71763	f1: 0.73645	P@1: 0	P@5: 0	P@8: 0	P@10: 0	P@15: 0
[MACRO]	accuracy: 0.52382	auc: 0.92698	precision: 0.70764	recall: 0.64481	f1: 0.67477	P@1: 0.88837	P@5: 0.67808	P@8: 0.54822	P@10: 0.47831	P@15: 0.35365

06:03:26 INFO ======== Results at level_1 ========
06:03:26 INFO Results on Valid set at epoch #5 with Loss 0.0253: 
[MICRO]	accuracy: 0.5493	auc: 0.94252	precision: 0.72132	recall: 0.69728	f1: 0.7091	P@1: 0	P@5: 0	P@8: 0	P@10: 0	P@15: 0
[MACRO]	accuracy: 0.50015	auc: 0.92246	precision: 0.67475	recall: 0.63226	f1: 0.65282	P@1: 0.86524	P@5: 0.66628	P@8: 0.54078	P@10: 0.4742	P@15: 0.35674

