{   'attention_mode': 'label',
    'batch_size': 8,
    'best_model_path': 'checkpoints/mimic-iii_2_50/RNN_LSTM_1_512.static.label.0.001.0.3_d7218b28bd55bc013ed4ef9dfd7a3379/best_model.pkl',
    'bidirectional': 1,
    'd_a': 512,
    'dropout': 0.3,
    'embedding_file': 'data/embeddings/word2vec_sg0_100.model',
    'embedding_mode': 'word2vec',
    'embedding_size': 100,
    'exp_name': 'gcn_single_sum',
    'hidden_size': 512,
    'joint_mode': 'hierarchical',
    'level_projection_size': 128,
    'loss_name': 'BCE',
    'lr': 0.001,
    'lr_scheduler_factor': 0.9,
    'lr_scheduler_patience': 5,
    'main_metric': 'micro_f1',
    'max_seq_length': 4000,
    'metric_level': 1,
    'min_seq_length': -1,
    'min_word_frequency': -1,
    'mode': 'static',
    'model': <class 'src.models.rnn.RNN'>,
    'multilabel': True,
    'n_epoch': 1,
    'n_labels': [34, 44],
    'n_layers': 1,
    'optimiser': 'adamw',
    'patience': 5,
    'penalisation_coeff': 0.01,
    'problem_name': 'mimic-iii_2_50',
    'r': -1,
    'reduction': 'sum',
    'result_path': 'checkpoints/mimic-iii_2_50/RNN_LSTM_1_512.static.label.0.001.0.3_d7218b28bd55bc013ed4ef9dfd7a3379/result.pkl',
    'resume_training': False,
    'rnn_model': 'LSTM',
    'save_best_model': True,
    'save_results': 1,
    'save_results_on_train': False,
    'shuffle_data': 1,
    'use_last_hidden_state': 0,
    'use_lr_scheduler': 1,
    'use_regularisation': False,
    'weight_decay': 0}